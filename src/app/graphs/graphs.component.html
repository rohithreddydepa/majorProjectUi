<h1 class="text-center">Graphs</h1>
<div
  class="grid"
  *ngFor="let item of graphs; let i = index"
  [ngClass]="{ 'grid-reverse': i === 1 }"
>
  <div>
    <app-graph [type]="item"></app-graph>
  </div>
  <div class="explain">
    <h1>{{ item }} graph</h1>
    F1Score: This score will give us the harmonic mean of precision and recall. Mathematically, F1 score is the weighted average of the precision and recall. The best value of F1 would be 1 and worst would be 0.
    Accuracy: Accuracy is the fraction of predictions our model got right out of all the predictions. This means that we sum the number of predictions correctly predicted as Positive (TP) or correctly predicted as Negative (TN) and divide it by all types of predictions, both correct (TP, TN) and incorrect (FP, FN).It ranges between 0 and 1.These extreme cases correspond to completely missing the predictions or having always correct predictions. 
    Recall: Recall aims at measuring what proportion of actual positives was identified correctly. It does so by dividing the correctly predicted positive samples (TP) by the total number of positives, either correctly predicted as positive or incorrectly predicted as negative (TP, FN).
    Precision: To overcome the limitations of Accuracy, Data Scientists usually use Precision, Recall and Specificity. Precision tells what proportion of positive predictions was actually correct. It achieves this by counting the samples correctly predicted as positive (TP) and dividing it by the total positive predictions, correct or incorrect (TP, FP).Accuracy, however, is not a great metric, especially when the data is imbalanced. 
  </div>
</div>
