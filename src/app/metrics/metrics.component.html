<h1 class="text-center">Performance Metrics</h1>
<div class="container">
  <div class="row">
    <div class="col-md-6">
      <app-table [tableName]="'Title'"></app-table>
    </div>
    <div class="col-md-6">
      <app-table [tableName]="'Body'"></app-table>
    </div>
  </div>
  <div class="row" style="justify-content: center">
    <div class="col-md-6">
      <app-table [tableName]="'TitleBody'"></app-table>
    </div>
  </div>
  <div class="row">
  <h4>Reference</h4>
  <p>Precision is a metric that quantifies the number of correct positive predictions made.Precision=TP/(TP+FP), <b>Higher the precision, better the model</b>.</p>
  <p>Recall is a metric that quantifies the number of correct positive predictions made out of all positive predictions that could have been made.Recall=TP/(TP+FN), <b>Higher the recall, better the model</b>.</p>
  <p>The F1 score is defined as the harmonic mean of precision and recall.F1 Score=2*(Precision * Recall)/(Precision + Recall), <b>Higher the F1 score, better the model</b>.</p>
  <p>Accuracy is the ratio of number of correct predictions to the total number of input samples.Accuracy=(TP+TN)/(TP+TN+FP+FN), <b>Higher the accuracy, better the model</b>.</p>
  <p>Hamming loss is the fraction of wrong labels to the total number of labels. Hamming Loss is a good measure of model performance, <b>Lower the hamming loss, better the model</b>.</p>
  <h6>Index</h6>
  <p>TP=true positives</p>
  <p>FP=false positives</p>
  <p>TN=true negatives</p>
  <p>FN=false negatives</p>
</div>
</div>
