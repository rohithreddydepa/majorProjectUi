<h1 class="text-center">Performance Metrics</h1>
<div class="container">
  <div class="row">
    <div class="col-md-6">
      <app-table [tableName]="'Title'"></app-table>
    </div>
    <div class="col-md-6">
      <app-table [tableName]="'Body'"></app-table>
    </div>
  </div>
  <div class="row" style="justify-content: center">
    <div class="col-md-6">
      <app-table [tableName]="'TitleBody'"></app-table>
    </div>
  </div>
  <div class="row">
    <h4 class="text-center">Reference</h4>
    <p>
      <b> Precision</b> is a metric that quantifies the number of correct
      positive predictions made.Precision=TP/(TP+FP),
      <b>Higher the precision, better the model</b>.
    </p>
    <p>
      <b> Recall</b> is a metric that quantifies the number of correct positive
      predictions made out of all positive predictions that could have been
      made.Recall=TP/(TP+FN), <b>Higher the recall, better the model</b>.
    </p>
    <p>
      The <b> F1 score</b> is defined as the harmonic mean of precision and
      recall. F1 Score=2*(Precision * Recall)/(Precision + Recall),
      <b>Higher the F1 score, better the model</b>.
    </p>
    <p>
      <b> Accuracy </b>is the ratio of number of correct predictions to the
      total number of input samples.Accuracy=(TP+TN)/(TP+TN+FP+FN),
      <b>Higher the accuracy, better the model</b>.
    </p>
    <p>
      <b> Hamming loss </b>is the fraction of wrong labels to the total number
      of labels. Hamming Loss is a good measure of model performance,
      <b>Lower the hamming loss, better the model</b>.
    </p>
    <h6>Index</h6>
    <p>TP=true positives</p>
    <p>FP=false positives</p>
    <p>TN=true negatives</p>
    <p>FN=false negatives</p>
  </div>
</div>
